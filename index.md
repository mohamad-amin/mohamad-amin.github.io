---
layout: homepage
---

## Hello friend,

I am a Ph.D. student at Toyota Technological Institute at Chicago ([TTIC](https://ttic.edu/)), where I'm fortunate to be advised by [Zhiyuan Li](https://zhiyuanli.ttic.edu/). I received my Master's degree at the Computer Science department of The University of British Columbia, where I was advised by [Danica J. Sutherland](https://djsutherland.ml/).

I use theoretical and empirical tools to study the foundations of Deep Learning, with a current focus on reasoning in Large Language Models. A desire to understand myself led me to this path.

## News

- **[Jan 2026]** I'll be spending summer 2026 at [Jane Street NYC](https://www.janestreet.com/) as a Machine Learning Research Intern. Let's grab a coffee and talk about Claude Code, [context rot](https://research.trychroma.com/context-rot) or Music ([not AI related](https://open.spotify.com/playlist/37i9dQZEVXdjDYnDdycFmw?si=e503cf20c5a24ec0)) if you're around!
- **[Nov 2025]** New preprint on enabling hesitation in LLMs through reinforcement learning from verifiable rewards is out on [arXiv](https://arxiv.org/abs/2511.11500)!
- **[Feb 2025]** Our paper on [Coordinate-wise Adaptivity of Adam](https://arxiv.org/abs/2410.08198) has been accepted to [ICLR 2025](https://iclr.cc/) as a **Spotlight**.
- **[Aug. 2024]** I'm a long term visitor at [Simons Institute for the Theory of Computing](https://simons.berkeley.edu/homepage) as part of the following programs: [Modern Paradigms on Generalization](https://simons.berkeley.edu/programs/modern-paradigms-generalization) and [Special Year On Large Langauge Models](https://simons.berkeley.edu/programs/special-year-large-language-models-transformers-part-1).
- **[March. 2023]** I'm giving a talk at Google Brain's (now DeepMind) PLAID team on my recent works about Neural Tangent Kernels.
- **[Dec. 2022]** I'm a recepient of NeurIPS 2022 Scholar Award.

{% include_relative _includes/publications.md %}

{% include_relative _includes/services.md %}

